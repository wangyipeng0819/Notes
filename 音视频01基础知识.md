---
title: 音视频基础知识
date: 2025-09-11 21:55:24
tags:
- 音视频基础
categories:
- 音视频开发
cover: https://bu.dusays.com/2025/09/15/68c78f0020a85.png
---

## 音视频编码流程

### 1.初始化和输入

`av_register_all()`：注册所有组件（旧版 FFmpeg 需要，最新版已经废弃）。

`avformat_open_input()`：打开媒体文件或网络流。

`avformat_find_stream_info()`：读取并解析流信息，找到音视频流。

### 2.寻找并打开编码器

- `avcodec_find_encoder()`：根据流的编码参数找到合适的编码器。
- `avcodec_open2()`：打开编码器，做好编码准备。

### 3.读取原始帧数据

- `av_read_frame()`：从输入流中读取数据（此时是未压缩或中间格式）。
- 判断是否获取到帧（`Get Frame?`）。

### 4.编码流程

- 拿到 **AVFrame**（音频/视频的原始帧数据）。
- 可选步骤：音频重采样 / 视频像素格式转换。
- `avcodec_send_frame()`：把 AVFrame 送入编码器。
- `avcodec_receive_packet()`：从编码器取出压缩后的 **AVPacket**。
- 循环执行，直到所有帧处理完成。

### 5.收尾

- 关闭资源，释放内存。

![](https://bu.dusays.com/2025/09/14/68c6bf1d5a035.png)



## 音视频解码流程

### 1.初始化和输入

- `av_register_all()`：注册所有组件（旧版）。
- `avformat_open_input()`：打开媒体文件或网络流。
- `avformat_find_stream_info()`：读取流信息，定位音频流/视频流。

### 2.寻找并打开解码器

- `avcodec_find_decoder()`：根据流信息找到合适的解码器。
- `avcodec_open2()`：打开解码器，准备解码。

### 3.读取压缩数据包

- `av_read_frame()`：读取一个 **AVPacket**（压缩的音视频数据）。
- 判断是否获取到包（`Get Packet?`）。

### 4.解码流程

- 拿到 **AVPacket**。
- `avcodec_send_packet()`：把压缩包送入解码器。
- `avcodec_receive_frame()`：从解码器获取到解码后的 **AVFrame**。
- 可选步骤：音频重采样 / 视频像素格式转换。
- 输出 **AVFrame**（原始 PCM 音频帧或 YUV 视频帧）。

### 5.收尾

- 关闭资源，释放内存。

![](https://bu.dusays.com/2025/09/14/68c6c6830aaf5.png)

### 总结：编码解码

编码（Encode）：
 原始帧 (**AVFrame**) → 压缩包 (**AVPacket**)
 `send_frame → receive_packet`

解码（Decode）：
 压缩包 (**AVPacket**) → 原始帧 (**AVFrame**)
 `send_packet → receive_frame`





### 一些疑问

#### 1.为什么要重采样？

![](https://bu.dusays.com/2025/09/14/68c6d38defdb1.png)

#### 2.视频格式转换

![](https://bu.dusays.com/2025/09/14/68c6d3b1168c9.png)



### FFmpeg封装格式转换

#### MP4转FLV

```c++
ffmpeg -i juren.mp4 -c copy juren.flv
```

ffmpeg根据文件的后缀名猜出封装格式，如果没有后缀名，ffmpeg就会读取一部分的文件内容来判断文件格式。所以ffmpeg非常智能，因为ffmpeg也是给非开发人员使用的。

对于一些新型的封装格式，ffmpeg 猜测不对，可以指定 封装格式，如下：

```
ffmpeg -f flv -i juren.flv -c copy juren.mp4
```

### 封装格式的使用场景

封装格式是多种多样的，为了解决不同的场景问题，大家会定义出来不同的格式。举个例子。

1，点播场景，什么是点播，就是视频已经录好了，放在服务器，客户端按需拉取一小端内容播放，不需要下载全部的视频内容。点播场景比较适合用 MP4 格式，因为 MP4 格式定义了 `stts` 索引表以及一些相关的数据结构，可以很快的跳转，例如 跳转 某个时间点播放，MP4 格式会比 FLV 快很多。（补充：FLV 可以额外添加 `keyframeindex` 加快跳转速度）

2，直播场景，MP4 格式的box结构要全部视频录完才能生成，而直播是不知道什么时候结束的。而 FLV 是一种渐进式的格式，非常适合用于直播。

所以不同的封装格式，是解决不同场景的问题。不过封装格式还会解决一些共同的问题，就是音视频同步。封装格式会给每个视频帧跟音频帧打上一个时间戳 PTS。

播放器单独播放视频流，或者音频流的时候，是不需要这个 PTS 时间戳的，视频流按帧率播放，音频流按采样率播放即可。这个 PTS 可以帮助音视频同步。

下面来讲解为什么，因为我们使用的操作系统大多都是**分时系统**，也就是每个任务分配一定的CPU时间片。

假设 Windows 系统正在播放一个视频（没有音频流），帧率是 1秒 24帧，现在是晚上 8点00分00秒。第一帧视频是从 8:00:00:00 开始播放，按帧率播放，41 毫秒就需要显示第二帧，所以第二帧应该在 8:00:00:41 的时候播放，第三帧在 8:00:00:82 的时候播放，这样画面看起来才是流畅的。但是由于是分时系统，在 8:00:00:41 的时候，CPU 在忙着干其他的任务，无法切换回来播放器线程。所以第二帧有可能是在 在 8:00:00:61 的时候才开始播放，慢了 20 毫秒。这种情况我们能怎么办？即使播放器是我们开发的，我们也什么都干不了，在某个时刻 CPU 就是忙不过来。第二帧慢了 20 毫秒，第三帧也慢20毫秒就行了。这样后面CPU不忙碌，看起来也会很流畅。这是单个视频流的情况。

假设有 一个音频流 与 一个视频流 同时播放，本来画面声音是需要同步的，例如第二帧视频播放的时候，第二帧音频也要播放。但是因为视频流慢了 20 毫秒，如果音频流的播放线程不理会 视频播放线程的卡顿情况，音频流还是按自己的采样率播放，就会导致音频流播放快于 视频流 20 毫秒，这样不断累计，音视频流就会逐渐差距很大，画面不同步。所以需要封装格式给 每个 音视频帧打上一个 PTS。音视频流 播放线程 通过观察对方 已经播放的 PTS 来决定自己要继续播放还是休眠，还是丢弃帧。

### FFmpeg封装格式转换

参考罗上文老师写的FFmpeg原理，地址：https://ffmpeg.xianwaizhiyin.net/

#### FLV转MP4

```
ffmpeg -i juren.flv juren.mp4
```

#### FLV转TS

```c++
ffmpeg -i juren.flv juren.ts
```

#### MP4转FLV

```c++
ffmpeg -i juren.mp4 juren.flv
```

上面的命令是 封装格式之间的转换，但是实际上会进行编解码转换，例如 MP4 转 FLV，他会先解码 MP4 的数据，然后 选择 FLV的默认的编码格式进行重新编码，FLV 封装格式的默认编码是 H.264，juren.mp4 的编码格式也是 H.264，**所以实际上编码格式没变**，但是还是经过了编解码运算。

为了加快运行速度，加上-c copy参数，让ffmpeg不进行编解码运算



### FFmpeg命令参数类型

![](https://bu.dusays.com/2025/09/14/68c6ca14db963.png)

1，可执行文件 ，就是 ffmpeg 那个软件。

2，输入文件参数，在 **-i** 前面那些参数，全部都作用于**当前**的输入文件。

3，输入文件名， **-i** 指定输入文件。

4，输出文件参数，输出文件名 前面的那些参数 就是输出文件参数，全部都作用于**当前**的输出文件。

5，输出文件名，juren.ts 就是输出文件名，输出文件名前面的一个参数不是 `-i`，也不是以 `-` 开始的参数。

6，全局参数， -y 跟 -benchmark 这些跟输入输出文件无关的参数就是全局参数。

为什么强调 **当前** ，是因为 ffmpeg 是支持多个输入文件跟多个输出文件的，多个文件可以有各自的**独立参数**。多输入文件在复杂滤镜的场景经常使用。

虽然ffmpeg有很多很多的命令参数，但是只要你记住 ffmpeg 的参数类型，就会很容易学会 其他 参数的使用。

另外一点，ffmpeg 的命令行参数是没有先后顺序的，我上图是比较正确的写法，先是输入，再是输出，最后是全局参数。

但是实际上，你可以把输出的命令参数放在前面。如下：

```
ffmpeg -c copy -t 10 -f mpegts juren.ts -ss 00:01:32 -f flv -i juren.flv -y -benchmark
```

你甚至可以把全局参数 插在 `-i` 前面，他依然是全局参数，不会被当成是输入文件参数，如下：

```
ffmpeg -c copy -t 10 -f mpegts juren.ts -ss 00:01:32 -f flv -y -benchmark -i juren.flv
```

### FFmpeg编码格式转换

现在演示一下 H.264 转 H.265 的 命令行语法，由于 FLV 目前官方不支持 H265，只能通过扩展字段自己加H265，没有标准。所以本文用 MP4 格式来演示，MP4 对 H.265 的支持是有标准定义的。

```
ffmpeg -i juren.mp4 -c:v hevc -c:a copy juren-h265.mp4
```

上面的 `-c` 是指定编码格式 ，v 跟 a 分别代表 视频 跟 音频，视频以 hevc 编码，音频不变直接 copy 到输出文件即可。H.265 就是 hevc。





### 🎬 FFmpeg 编码流程梳理

#### 1. 查找并初始化编码器

- `avcodec_find_encoder()`
   根据指定的编码格式（如 H.264、AAC）找到对应的编码器。
- `avcodec_alloc_context3()`
   分配编码器上下文（`AVCodecContext`），用于保存编码所需的参数。
- **设置编码参数**
   包括码率（bitrate）、分辨率、帧率、像素格式、声道数、采样率等。

------

#### 2. 打开编码器

- `avcodec_open2()`
   打开编码器，准备进行编码。

------

#### 3. 分配数据结构

- `av_packet_alloc()`
   分配 `AVPacket`，用于存储编码后的压缩数据。
- `av_frame_alloc()`
   分配 `AVFrame`，用于存储原始音频/视频帧数据。
- **设置 Frame 参数**
   设置 `AVFrame` 的格式（像素格式/采样格式）、宽高（视频）或声道/采样率（音频）。
- `av_frame_get_buffer()`
   为 `AVFrame` 分配真正的缓冲区，存放原始采样数据。

------

#### 4. 读取数据并送入编码器

- **读取文件/原始数据**
   从输入源（文件、摄像头、音频采集）获取一帧数据，填充到 `AVFrame`。
- `avcodec_send_frame()`
   将原始帧（AVFrame）送入编码器。
- `avcodec_receive_packet()`
   从编码器中取出压缩后的数据包（AVPacket）。
- **写文件**
   将 `AVPacket` 写入输出文件（例如 `.h264`, `.aac`, `.mp4` 等）。

------

#### 5. 循环处理

- 上述 **读数据 → 编码 → 写数据** 循环，直到输入数据全部处理完。

------

#### 6. 收尾 (Flush & 释放资源)

- `flush_encode`
   在输入结束后，调用 `avcodec_send_frame(NULL)` 通知编码器刷出缓存中尚未输出的帧。
   再循环调用 `avcodec_receive_packet()` 获取剩余数据。
- **释放资源**
   `av_frame_free()`、`av_packet_free()`、`avcodec_free_context()`、`avformat_free_context()`。
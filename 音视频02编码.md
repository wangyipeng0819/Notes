---
title: 音视频编码
date: 2025-09-15 11:55:08
tags:
- 编解码
categories:
- 音视频开发
cover: https://bu.dusays.com/2025/09/15/68c78f0020a85.png
---

## 视频编码

### 准备工作

将mp4文件提取其中的视频数据转为yuv420p

```
ffmpeg -i input.mp4 -pixel_format yuv420p -s 1280x720 output.yuv 
```

对于h264文件可以直接使用ffplay播放

```
ffplay -i input.264
```



```C++
// 准备yuv文件

// 引入ffmpeg库

#include <QDebug>

extern "C"
{
#include <libavcodec/avcodec.h>
}
const char* inFileName = "D:\\code\\ffmpeg\\output.yuv"; //输入文件的路径及名称，裸流yuv文件
const char* outFileName = "output.h264";  // 输出为l

// 编码上下文、复用使用的单个 AVPacket
//一帧像素数据（或 nullptr 触发 flush）、输出文件句柄。

// 参数1：编码器上下文  avcodec_alloc_context3() 创建并 avcodec_open2() 初始化过
// 参数2：AVPacket* packet：外部分配好的压缩包容器，用于接收编码后的数据。
// 参数3：AVFrame* frame：要编码的一帧图像，如果是 nullptr，表示 flush（冲刷编码器）。
// 参数4：FILE* outFile：目标输出文件句柄（如 .h264）。
int encode(AVCodecContext* codeContent, AVPacket* packet,AVFrame* frame,FILE* outFile)
{
    // AVFrame 是原始数据（像素 / 音频采样），AVPacket 是压缩后的数据（码流）。
    // 将第一个原始帧 发送给编码器
    int ret = avcodec_send_frame(codeContent,frame);
    if (ret < 0)
    {
        qDebug() << "Error sending a frame for encoding！";
        return -1;
    }
    // 开始接收编码后的压缩包（循环）
    while (ret == 0)
    {
        // packet 将指向编码后的数据  尝试取出压缩的数据包
        ret = avcodec_receive_packet(codeContent,packet);
        // 处理无法立即接收包的情况（正常退出）
        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF){
            return 0;
        }
        else if (ret < 0)
        {
            qDebug() << "ERROR encoding video frame";
            return -1;
        }
        // 收到编码后的压缩包 ，直接写入文件
        if (ret == 0)
        {
            fwrite(packet->data, 1, packet->size,outFile);
        }
    }
}
int main(int argc, char* argv[])
{
    int ret = 0;

    // 准备编码器
    const AVCodec* codec = nullptr;  // 编码器对象指针
    AVCodecContext* codecContent = nullptr; // 编码器上下文
    AVPacket* packet = nullptr;  //AVPacket，编码器输出的每个压缩帧（.h264一段码流），就是一个AVPacket
    AVFrame* frame = nullptr;    //喂给编码器的输入数据结构

    FILE* inFile = nullptr;  // 原始文件  帧数据  读取yuv文件
    FILE* outFile = nullptr;   // 编码生成后的文件

    codec = avcodec_find_encoder(AV_CODEC_ID_H264);
    if (codec == nullptr)
    {
        qDebug() << "could not find H264 encoder!!";
        return -1;
    }

    // 分配编码器上下文
    codecContent = avcodec_alloc_context3(codec);
    if (codecContent == nullptr)
    {
        qDebug() << "could not alloc context!!";
        return -1;
    }

    // 设置参数了
    codecContent->width = 1280;
    codecContent->height = 720;
    codecContent->time_base = AVRational{1,25};  // 时序
    codecContent->pix_fmt = AV_PIX_FMT_YUV420P;
    codecContent->framerate = AVRational{25,1};

    // 初始化编码器上下文
    // 打开编码器
    ret = avcodec_open2(codecContent, codec, NULL);
    if (ret < 0)
    {
        qDebug() << "could not open codec!!";
        exit(1);
    }

    // 分配数据结构  用于存储编码后的压缩数据
    packet = av_packet_alloc();
    if (packet == nullptr)
    {
        qDebug() << "could not alloc packet!!";
        return -1;
    }

    // 存原始音视频帧数据
    frame = av_frame_alloc();  // 只分配结构体本身，不包括里面的数据
    if (frame == nullptr)
    {
        qDebug() << "could not alloc frame!!";
        return -1;
    }
    // 让 frame 的格式与编码器一致，便于直接送入编码器。
    // 设置 AVFrame的格式  宽高  采样格式
    frame->width = codecContent->width;
    frame->height = codecContent->height;
    frame->format = codecContent->pix_fmt;

    // 为每个plane分配对齐后的行缓冲
    // `AVFrame` 分配真正的缓冲区，存放原始采样数据。
    ret = av_frame_get_buffer(frame, 0);
    if (ret)
    {
        qDebug() <<"alloc frame buffer error!";
        return -1;
    }

    // 读数据
    inFile = fopen(inFileName,"rb");

    if (inFile == nullptr)
    {
        qDebug() <<"open file error!";
        return -1;
    }
    outFile = fopen(outFileName,"wb");
    if (outFile == nullptr)
    {
        qDebug() <<"open file error2!";
        return -1;
    }
    // 以 feof 驱动循环。注意：feof 只有在上一次读取失败后才置位
    // 典型副作用是会多进入一次循环。
    // feof(inFile)读完之后才变为 true
    while(!feof(inFile))
    {
        ret = av_frame_is_writable(frame); // 判断是否可写
        if (ret < 0)
        {
            ret = av_frame_make_writable(frame);
        }
        // 读取YUV图像数据  YUV420
        fread(frame->data[0], 1,frame->width*frame->height,inFile);
        fread(frame->data[1], 1,frame->width*frame->height/4,inFile);
        fread(frame->data[2], 1,frame->width*frame->height/4,inFile);

        qDebug() << "encoder  frame";
        encode(codecContent,packet,frame,outFile);// 进行 编码
    }
    // 向编码器传入 NULL AVFrame 是 FFmpeg 的规范操作，用于告诉编码器：
    // “我已经没有更多帧要送进来了，你可以把缓冲区里剩余的数据都吐出来了。”
    // 编码器内部往往是“有延迟”的，比如 B 帧需要缓存多个帧才能编码；
    // 如果你只是编码完最后一帧就停了，缓冲区里的压缩数据可能丢失；
    // 所以我们用 nullptr 调用一次 encode() 来清空编码器的缓存。
    encode(codecContent,packet,frame,outFile);
    qDebug() << "encoder  finish";
    av_packet_free(&packet);
    av_frame_free(&frame);
    avcodec_free_context(&codecContent);
    fclose(inFile);
    fclose(outFile);

    return 0;
}
```

## 音频编码

### 准备工作

FFmpeg将音频从input.mp4中提取出来，并重采样、转码为裸PCM数据。

```
ffmpeg -i input.mp4 -ar 44100 -ac 2 -f s16le output.pcm
```

采样频率 44100Hz  通道数为 2   （-ac）

通过命令播放AAC音频文件

```
ffplay -i output.aac
```



```c++
#include <QDebug>
extern "C"
{
#include "libavcodec/avcodec.h"
#include "libavformat/avformat.h"
#include "libswresample/swresample.h"
}

int main(){
    char inputfile[] = "D:\\code\\ffmpeg\\output.pcm";
    char outputfile[] = "audio.aac";
    const AVCodec* avCodec = avcodec_find_encoder(AV_CODEC_ID_AAC);
    if(!avCodec){
        qDebug() << "avcodec_find_encoder failed";
        return -1;
    }
    AVCodecContext* avCodecContext = avcodec_alloc_context3(avCodec);
    if(!avCodecContext){
        qDebug() << "avcodec_alloc_context3 failed";
        return -1;
    }
    int ret=0;
    // 采样率
    avCodecContext->sample_rate = 44100;
    avCodecContext->channels = 2;  // 声音数，2  表示立体声
    avCodecContext->sample_fmt = AV_SAMPLE_FMT_FLTP;  //输入采样格式（采样精度+存储方式）
    //左通道：[0.1, 0.2, 0.3, ...]    FLTP  每个通道的数据是分开存储的
	//右通道：[0.4, 0.5, 0.6, ...]
    
    avCodecContext->bit_rate = 64000;  // 目标比特率，比特率越高音频质量越好  文件越大
    // 声道布局  标准立体声（左 + 右）。 必须与channels一致
    avCodecContext->channel_layout = AV_CH_LAYOUT_STEREO;
    ret = avcodec_open2(avCodecContext, avCodec,NULL);  // 打开编码器上下文
    if(ret<0){
        qDebug() << "avcodec_open2 failed";
        return -1;
    }
    // 为输出对象创建格式上下文对象
    AVFormatContext* avFormatContext = NULL;
    // NULL, NULL, outputfile 代表自动根据 outputfile 后缀推测格式（如 .aac → aac）。
    avformat_alloc_output_context2(&avFormatContext, NULL, NULL, outputfile);
    if(!avFormatContext){
        qDebug() << "avformat_alloc_output_context2 failed";
        return -1;
    }
    // 在封装的容器内创建一个音频流--用来描述这个音频流的参数（编码方式 时间戳）
    AVStream* st = avformat_new_stream(avFormatContext, NULL);
    st->codecpar->codec_tag = 0;
    // 将编码器中的参数复制到AVStream->codecpar
    avcodec_parameters_from_context(st->codecpar, avCodecContext);
    // 打开输出文件  准备写入内容
    ret = avio_open(&avFormatContext->pb, outputfile, AVIO_FLAG_WRITE);
    if(ret<0){
        qDebug() << "avio_open failed";
            return -1;
    }
    // 向输出文件写入封装头信息（即 .aac 文件的头部）。
    avformat_write_header(avFormatContext, NULL);

    // FFmpeg 的重采样上下文
    SwrContext* swrContext = NULL;
    // 设置参数， 1. 上下文 2.输出声道布局 4.输出采样率, 5.输入声道布局 6.输入样本格式 7.输入采样率 8.配音 9.日志
    // 将输入格式转换为编码器需要的输出格式：
    swrContext = swr_alloc_set_opts(swrContext, avCodecContext->channel_layout, avCodecContext->sample_fmt, avCodecContext->sample_rate,
                                    AV_CH_LAYOUT_STEREO, AV_SAMPLE_FMT_S16, 44100,
                                    0, 0);
    if(!swrContext){
            qDebug() << "swr_alloc_set_opts failed";
            return -1;
    }
    // 初始化
    ret = swr_init(swrContext);
    if(ret<0){
            qDebug() << "swr_init failed";
            return -1;
    }
	// AVFrame
    AVFrame* avFrame = av_frame_alloc();
    avFrame->format = AV_SAMPLE_FMT_FLTP;
    avFrame->channels=2;
    avFrame->channel_layout = AV_CH_LAYOUT_STEREO;
    avFrame->nb_samples=1024;
    ret = av_frame_get_buffer(avFrame, 0);
    if(ret<0){
        qDebug() << "av_frame_get_buffer failed";
        return -1;
    }
    // 读取原始的PCM数据
    int readSize = avFrame->nb_samples*2*2;// 双声道 * 每采样2字节（16bit） * 采样数
    char* pcms = new char[readSize];
    FILE* fp = fopen(inputfile, "rb");
    for(;;){
        AVPacket pkt;  // 初始化packet   读取 pcm数据
        av_init_packet(&pkt);
        int len = fread(pcms,1,readSize, fp); // 一次读取一帧大小的pcm原始数据
        if(len <=0){ 
            break;
        }else{
            // 重采样 s16->fltp
            const uint8_t* data[1]; // 指针数组
            
            
            /*这里只用 data[0] 是因为 AV_SAMPLE_FMT_S16 是 interleaved 格式
             → 所有声道在一个数组里交错排布。*/
            data[0] = (uint8_t*)pcms;  //让指针指向pcms这块内存
            // 将其转为 AAC 编码器要求的 float planar 格式。
            // 这一步就实现了从 交错整型（s16）→ 平面浮点（fltp） 的格式转换，并写入 AVFrame 中。
            len = swr_convert(swrContext, avFrame->data, avFrame->nb_samples, data, avFrame->nb_samples);
            if(len <=0){
                qDebug() << "swr_convert failed";
                    break;
            }
            ret = avcodec_send_frame(avCodecContext, avFrame);
            if(ret < 0){
                qDebug() << "avcodec_send_frame failed";
                continue;
            }
            ret = avcodec_receive_packet(avCodecContext, &pkt);
            if(ret == 0){// 将该包写入文件或封装格式中
               av_interleaved_write_frame(avFormatContext, &pkt);
            }
        }
    }
    // 必须在所有 av_interleaved_write_frame() 完成之后调用
    av_write_trailer(avFormatContext); // 写入容器格式的结尾信息
    fclose(fp);
    avio_close(avFormatContext->pb);
    avcodec_close(avCodecContext);
    avcodec_free_context(&avCodecContext);
    avformat_free_context(avFormatContext);
    return 0;
}

```

```
            +--------------------+
            |   PCM 原始数据     |
            +--------------------+
                      |
                      v
            +--------------------+
            | 重采样（可选）     |  swr_convert()
            | s16 → fltp         |
            +--------------------+
                      |
                      v
            +--------------------+
            | 编码器发送帧       |  avcodec_send_frame()
            +--------------------+
                      |
                      v
            +--------------------+
            | 编码器输出Packet   |  avcodec_receive_packet()
            +--------------------+
                      |
                      v
            +--------------------+
            | 写入文件（封装）   |  av_interleaved_write_frame()
            +--------------------+
```

